<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 1: Introduction to Emotion AI - WIA Emotion AI Standard Ebook</title>
</head>
<body>

<p><a href="index.html">ðŸ’— WIA Emotion AI Standard Ebook</a> | Chapter 1 of 8</p>

<hr>

<h1>ðŸ’— Chapter 1: Introduction to Emotion AI</h1>

<blockquote>
<p><strong>Hongik Ingan (å¼˜ç›Šäººé–“)</strong></p>
<p>"Benefit All Humanity"</p>
<p>The WIA Emotion AI Standard is built on the philosophy that understanding human emotions is fundamental to creating technology that truly serves humanity.</p>
</blockquote>

<hr>

<h2>1.1 What is Emotion AI (Affective Computing)?</h2>

<p><strong>Emotion AI</strong>, also known as <strong>Affective Computing</strong>, is a multidisciplinary field that combines artificial intelligence, computer science, psychology, and cognitive science to develop systems that can recognize, interpret, process, and simulate human emotions.</p>

<p>[i] <strong>Definition:</strong> Affective Computing is the study and development of systems and devices that can recognize, interpret, process, and simulate human affects (emotions, moods, and attitudes).</p>

<h3>1.1.1 The Origin: Rosalind Picard</h3>

<p>The field of Affective Computing was established by <strong>Dr. Rosalind Picard</strong> at the MIT Media Lab in 1995. Her seminal paper "Affective Computing" laid the foundation for what would become a multi-billion dollar industry.</p>

<table border="1" cellpadding="10">
    <tr>
        <td><strong>Founder</strong></td>
        <td>Rosalind Picard, Sc.D.</td>
    </tr>
    <tr>
        <td><strong>Institution</strong></td>
        <td>MIT Media Lab</td>
    </tr>
    <tr>
        <td><strong>Year</strong></td>
        <td>1995</td>
    </tr>
    <tr>
        <td><strong>Key Publication</strong></td>
        <td>"Affective Computing" (1997 book)</td>
    </tr>
    <tr>
        <td><strong>Core Thesis</strong></td>
        <td>Emotions are essential to human intelligence and decision-making</td>
    </tr>
</table>

<h3>1.1.2 Why Emotions Matter in Computing</h3>

<p>Picard's groundbreaking insight was that emotions are not separate from rational thoughtâ€”they are essential to it. Research in neuroscience, particularly by Antonio Damasio, showed that people with damage to emotional centers of the brain struggle to make even simple decisions.</p>

<p><strong>Key Insights:</strong></p>
<ul>
    <li>Emotions guide attention and memory</li>
    <li>Emotional responses are faster than cognitive processing</li>
    <li>Human-computer interaction is inherently emotional</li>
    <li>Machines that understand emotions can better serve humans</li>
</ul>

<hr>

<h2>1.2 Market Size and Growth</h2>

<p>The Emotion AI market has experienced explosive growth and is projected to continue expanding rapidly:</p>

<table border="1" cellpadding="10">
    <thead>
        <tr>
            <th>Year</th>
            <th>Market Size (USD)</th>
            <th>Growth Rate</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>2020</td>
            <td>$21.6 billion</td>
            <td>-</td>
        </tr>
        <tr>
            <td>2021</td>
            <td>$24.8 billion</td>
            <td>14.8%</td>
        </tr>
        <tr>
            <td>2022</td>
            <td>$28.5 billion</td>
            <td>14.9%</td>
        </tr>
        <tr>
            <td>2023</td>
            <td>$32.7 billion</td>
            <td>14.7%</td>
        </tr>
        <tr>
            <td>2026 (projected)</td>
            <td>$37.1 billion</td>
            <td>CAGR 13.5%</td>
        </tr>
    </tbody>
</table>

<h3>1.2.1 Market Segments</h3>

<p>The Emotion AI market spans multiple industry verticals:</p>

<ul>
    <li><strong>Healthcare (28%)</strong> - Mental health monitoring, patient care</li>
    <li><strong>Retail/Marketing (24%)</strong> - Consumer research, advertising effectiveness</li>
    <li><strong>Automotive (18%)</strong> - Driver monitoring systems</li>
    <li><strong>Media/Entertainment (15%)</strong> - Content optimization, gaming</li>
    <li><strong>Education (10%)</strong> - Adaptive learning, student engagement</li>
    <li><strong>Other (5%)</strong> - Security, accessibility, customer service</li>
</ul>

<hr>

<h2>1.3 Emotion Classification Models</h2>

<h3>1.3.1 Ekman's Discrete Model (6 Basic Emotions)</h3>

<p>Dr. Paul Ekman's research in the 1970s identified six universal emotions that are recognized across all human cultures:</p>

<table border="1" cellpadding="10">
    <thead>
        <tr>
            <th>Emotion</th>
            <th>Description</th>
            <th>Facial Characteristics</th>
            <th>Universal Recognition</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td><strong>ðŸ˜Š Happiness</strong></td>
            <td>Positive emotional state of joy</td>
            <td>Raised cheeks, crow's feet, lip corners up</td>
            <td>93%</td>
        </tr>
        <tr>
            <td><strong>ðŸ˜¢ Sadness</strong></td>
            <td>Emotional pain and sorrow</td>
            <td>Inner brow raised, lip corners down</td>
            <td>84%</td>
        </tr>
        <tr>
            <td><strong>ðŸ˜  Anger</strong></td>
            <td>Strong displeasure response</td>
            <td>Lowered brows, tense jaw, narrowed eyes</td>
            <td>90%</td>
        </tr>
        <tr>
            <td><strong>ðŸ˜¨ Fear</strong></td>
            <td>Response to perceived threat</td>
            <td>Wide eyes, raised brows, open mouth</td>
            <td>85%</td>
        </tr>
        <tr>
            <td><strong>ðŸ¤¢ Disgust</strong></td>
            <td>Revulsion or strong disapproval</td>
            <td>Wrinkled nose, raised upper lip</td>
            <td>88%</td>
        </tr>
        <tr>
            <td><strong>ðŸ˜® Surprise</strong></td>
            <td>Brief emotional response to unexpected</td>
            <td>Raised brows, wide eyes, dropped jaw</td>
            <td>81%</td>
        </tr>
    </tbody>
</table>

<p>[i] <strong>Note:</strong> WIA Emotion AI Standard also includes <strong>Neutral</strong> as a seventh category, representing the absence of strong emotional expression.</p>

<h3>1.3.2 The Dimensional Model (Valence-Arousal)</h3>

<p>The dimensional model, developed by James Russell, represents emotions on a continuous two-dimensional space:</p>

<pre>
                    High Arousal
                         |
                    Excited | Tense
                         |
    Negative ----+-------+-------+---- Positive
    Valence      |       |       |     Valence
                    Bored   | Content
                         |
                    Low Arousal

Quadrant Mapping:
  High Valence + High Arousal = Excited, Happy, Elated
  High Valence + Low Arousal  = Calm, Relaxed, Serene
  Low Valence  + High Arousal = Angry, Afraid, Stressed
  Low Valence  + Low Arousal  = Sad, Depressed, Bored
</pre>

<p><strong>Valence:</strong> Ranges from -1 (negative) to +1 (positive), representing the pleasantness of an emotion.</p>
<p><strong>Arousal:</strong> Ranges from -1 (low activation) to +1 (high activation), representing the intensity or energy level.</p>

<hr>

<h2>1.4 FACS - Facial Action Coding System</h2>

<h3>1.4.1 History and Development</h3>

<p>The Facial Action Coding System (FACS) was developed by Paul Ekman and Wallace V. Friesen in 1978. It provides a systematic way to describe facial movements in terms of Action Units (AUs).</p>

<h3>1.4.2 Action Units</h3>

<p>Action Units represent the contraction or relaxation of specific facial muscles. Each AU is assigned a number and name:</p>

<table border="1" cellpadding="10">
    <thead>
        <tr>
            <th>AU</th>
            <th>FACS Name</th>
            <th>Muscles</th>
            <th>Description</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>AU1</td>
            <td>Inner Brow Raiser</td>
            <td>Frontalis (pars medialis)</td>
            <td>Raises inner portion of eyebrows</td>
        </tr>
        <tr>
            <td>AU2</td>
            <td>Outer Brow Raiser</td>
            <td>Frontalis (pars lateralis)</td>
            <td>Raises outer portion of eyebrows</td>
        </tr>
        <tr>
            <td>AU4</td>
            <td>Brow Lowerer</td>
            <td>Corrugator supercilii, Depressor supercilii</td>
            <td>Lowers and draws eyebrows together</td>
        </tr>
        <tr>
            <td>AU5</td>
            <td>Upper Lid Raiser</td>
            <td>Levator palpebrae superioris</td>
            <td>Raises upper eyelid</td>
        </tr>
        <tr>
            <td>AU6</td>
            <td>Cheek Raiser</td>
            <td>Orbicularis oculi (pars orbitalis)</td>
            <td>Raises cheeks, creates crow's feet</td>
        </tr>
        <tr>
            <td>AU7</td>
            <td>Lid Tightener</td>
            <td>Orbicularis oculi (pars palpebralis)</td>
            <td>Tightens eyelids</td>
        </tr>
        <tr>
            <td>AU9</td>
            <td>Nose Wrinkler</td>
            <td>Levator labii superioris alaeque nasi</td>
            <td>Wrinkles nose</td>
        </tr>
        <tr>
            <td>AU10</td>
            <td>Upper Lip Raiser</td>
            <td>Levator labii superioris</td>
            <td>Raises upper lip</td>
        </tr>
        <tr>
            <td>AU12</td>
            <td>Lip Corner Puller</td>
            <td>Zygomaticus major</td>
            <td>Pulls lip corners up (smile)</td>
        </tr>
        <tr>
            <td>AU15</td>
            <td>Lip Corner Depressor</td>
            <td>Depressor anguli oris</td>
            <td>Pulls lip corners down (frown)</td>
        </tr>
        <tr>
            <td>AU17</td>
            <td>Chin Raiser</td>
            <td>Mentalis</td>
            <td>Raises chin</td>
        </tr>
        <tr>
            <td>AU20</td>
            <td>Lip Stretcher</td>
            <td>Risorius</td>
            <td>Stretches lips horizontally</td>
        </tr>
        <tr>
            <td>AU23</td>
            <td>Lip Tightener</td>
            <td>Orbicularis oris</td>
            <td>Tightens lips</td>
        </tr>
        <tr>
            <td>AU24</td>
            <td>Lip Pressor</td>
            <td>Orbicularis oris</td>
            <td>Presses lips together</td>
        </tr>
        <tr>
            <td>AU25</td>
            <td>Lips Part</td>
            <td>Depressor labii inferioris, Relaxation of Mentalis</td>
            <td>Parts lips</td>
        </tr>
        <tr>
            <td>AU26</td>
            <td>Jaw Drop</td>
            <td>Masseter, Temporalis</td>
            <td>Drops jaw/opens mouth</td>
        </tr>
    </tbody>
</table>

<h3>1.4.3 Emotion-AU Mapping</h3>

<p>Each basic emotion can be described by a combination of Action Units:</p>

<table border="1" cellpadding="10">
    <thead>
        <tr>
            <th>Emotion</th>
            <th>Typical AU Combination</th>
            <th>Description</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Happiness</td>
            <td>AU6 + AU12</td>
            <td>Cheek raiser + Lip corner puller (Duchenne smile)</td>
        </tr>
        <tr>
            <td>Sadness</td>
            <td>AU1 + AU4 + AU15</td>
            <td>Inner brow raise + Brow lower + Lip corner depress</td>
        </tr>
        <tr>
            <td>Anger</td>
            <td>AU4 + AU5 + AU7 + AU23</td>
            <td>Brow lower + Upper lid raise + Lid tighten + Lip tighten</td>
        </tr>
        <tr>
            <td>Fear</td>
            <td>AU1 + AU2 + AU4 + AU5 + AU20 + AU26</td>
            <td>Brow raise + Brow lower + Upper lid raise + Lip stretch + Jaw drop</td>
        </tr>
        <tr>
            <td>Disgust</td>
            <td>AU9 + AU15 + AU16</td>
            <td>Nose wrinkle + Lip corner depress + Lower lip depress</td>
        </tr>
        <tr>
            <td>Surprise</td>
            <td>AU1 + AU2 + AU5 + AU26</td>
            <td>Brow raise + Upper lid raise + Jaw drop</td>
        </tr>
    </tbody>
</table>

<hr>

<h2>1.5 Input Modalities</h2>

<p>Emotion AI systems can analyze emotions through multiple input channels:</p>

<h3>1.5.1 Facial Expression Analysis</h3>

<ul>
    <li><strong>Input:</strong> Camera/video feed</li>
    <li><strong>Technology:</strong> Computer Vision, CNN, Deep Learning</li>
    <li><strong>Output:</strong> Emotion labels, AU intensities, V-A coordinates</li>
    <li><strong>Accuracy:</strong> 85-95% on frontal faces</li>
    <li><strong>Challenges:</strong> Pose variation, lighting, occlusion</li>
</ul>

<h3>1.5.2 Voice/Speech Analysis</h3>

<ul>
    <li><strong>Input:</strong> Audio signal</li>
    <li><strong>Technology:</strong> Speech recognition, Acoustic feature extraction</li>
    <li><strong>Features:</strong> Pitch, intensity, speech rate, voice quality</li>
    <li><strong>Accuracy:</strong> 70-85%</li>
    <li><strong>Challenges:</strong> Background noise, language variation</li>
</ul>

<h3>1.5.3 Text Sentiment Analysis</h3>

<ul>
    <li><strong>Input:</strong> Text (chat, social media, reviews)</li>
    <li><strong>Technology:</strong> NLP, Transformer models, BERT</li>
    <li><strong>Output:</strong> Sentiment polarity, emotion categories</li>
    <li><strong>Accuracy:</strong> 80-90%</li>
    <li><strong>Challenges:</strong> Sarcasm, context, cultural nuances</li>
</ul>

<h3>1.5.4 Biosignal Analysis</h3>

<ul>
    <li><strong>Input:</strong> Physiological sensors (ECG, EDA, EEG)</li>
    <li><strong>Signals:</strong>
        <ul>
            <li>Heart Rate Variability (HRV)</li>
            <li>Electrodermal Activity (EDA/GSR)</li>
            <li>Electroencephalography (EEG)</li>
            <li>Respiration rate</li>
        </ul>
    </li>
    <li><strong>Accuracy:</strong> 75-85%</li>
    <li><strong>Advantage:</strong> Hard to fake, continuous monitoring</li>
</ul>

<hr>

<h2>1.6 Major Use Cases</h2>

<h3>1.6.1 Healthcare</h3>

<ul>
    <li><strong>Mental Health Monitoring:</strong> Track depression, anxiety, PTSD symptoms</li>
    <li><strong>Telehealth:</strong> Assess patient emotional state during video consultations</li>
    <li><strong>Autism Research:</strong> Analyze emotional expression patterns</li>
    <li><strong>Pain Assessment:</strong> Detect pain in non-verbal patients</li>
</ul>

<h3>1.6.2 Marketing and Consumer Research</h3>

<ul>
    <li><strong>Ad Testing:</strong> Measure emotional response to advertisements</li>
    <li><strong>Product Design:</strong> Assess user reactions to prototypes</li>
    <li><strong>Brand Perception:</strong> Analyze consumer sentiment</li>
    <li><strong>Store Experience:</strong> Monitor shopper emotions in retail</li>
</ul>

<h3>1.6.3 Education</h3>

<ul>
    <li><strong>Engagement Detection:</strong> Identify confused or bored students</li>
    <li><strong>Adaptive Learning:</strong> Adjust content based on emotional state</li>
    <li><strong>Online Proctoring:</strong> Monitor test-taking stress levels</li>
    <li><strong>Teacher Training:</strong> Provide feedback on classroom dynamics</li>
</ul>

<h3>1.6.4 Customer Service</h3>

<ul>
    <li><strong>Call Centers:</strong> Detect frustrated callers for escalation</li>
    <li><strong>Chatbots:</strong> Adapt responses to user sentiment</li>
    <li><strong>Complaint Detection:</strong> Early warning for dissatisfied customers</li>
</ul>

<h3>1.6.5 Automotive</h3>

<ul>
    <li><strong>Driver Monitoring:</strong> Detect drowsiness, distraction, anger</li>
    <li><strong>Safety Alerts:</strong> Trigger warnings or interventions</li>
    <li><strong>Autonomous Vehicles:</strong> Understand passenger comfort</li>
</ul>

<h3>1.6.6 Gaming and XR</h3>

<ul>
    <li><strong>NPC Reactions:</strong> Characters respond to player emotions</li>
    <li><strong>Difficulty Adjustment:</strong> Adapt game based on frustration/enjoyment</li>
    <li><strong>VR Experiences:</strong> Create immersive emotional journeys</li>
</ul>

<h3>1.6.7 Accessibility</h3>

<ul>
    <li><strong>BIGEKO Project:</strong> Emotion recognition in sign language</li>
    <li><strong>Communication Aids:</strong> Help non-verbal individuals express emotions</li>
</ul>

<hr>

<h2>1.7 WIA Philosophy: Hongik Ingan</h2>

<blockquote>
<p><strong>å¼˜ç›Šäººé–“ (Hongik Ingan)</strong></p>
<p>"Benefit All Humanity"</p>
<p>This ancient Korean philosophy guides the WIA Emotion AI Standard. We believe that:</p>
<ul>
    <li>Emotion AI should be ethical and privacy-respecting</li>
    <li>Standards should be open and accessible to all</li>
    <li>Technology should serve human wellbeing</li>
    <li>Cultural diversity in emotion expression must be respected</li>
</ul>
</blockquote>

<hr>

<h2>1.8 Chapter Summary</h2>

<p>[OK] <strong>Key Takeaways:</strong></p>

<ol>
    <li><strong>Definition:</strong> Emotion AI (Affective Computing) enables machines to recognize and respond to human emotions</li>
    <li><strong>Origin:</strong> Founded by Rosalind Picard at MIT Media Lab in 1995</li>
    <li><strong>Market:</strong> Projected to reach $37.1 billion by 2026</li>
    <li><strong>Models:</strong> Ekman's discrete model (6 emotions) and dimensional model (Valence-Arousal)</li>
    <li><strong>FACS:</strong> Systematic coding of facial expressions using Action Units</li>
    <li><strong>Modalities:</strong> Face, voice, text, and biosignals</li>
    <li><strong>Applications:</strong> Healthcare, marketing, education, automotive, gaming</li>
</ol>

<hr>

<h2>1.9 Review Questions</h2>

<ol>
    <li>Who founded the field of Affective Computing and when?</li>
    <li>Name the six basic emotions identified by Paul Ekman.</li>
    <li>What are the two dimensions in the Valence-Arousal model?</li>
    <li>What is FACS and what are Action Units?</li>
    <li>List four input modalities for emotion recognition.</li>
    <li>Describe three use cases for Emotion AI in healthcare.</li>
</ol>

<hr>

<h2>1.10 Looking Ahead</h2>

<p>In Chapter 2, we will explore the current challenges in Emotion AI, including cultural differences, privacy concerns, accuracy limitations, and the critical need for standardization that the WIA Emotion AI Standard addresses.</p>

<hr>

<p><strong>Chapter 1 Complete</strong> | Approximate pages: 16</p>

<p><a href="chapter-02.html">Next: Chapter 2 - Current Challenges</a></p>

<hr>

<p><strong>WIA - World Certification Industry Association</strong></p>
<p>Hongik Ingan - Benefit All Humanity</p>
<p><a href="https://wiastandards.com">https://wiastandards.com</a></p>

</body>
</html>
