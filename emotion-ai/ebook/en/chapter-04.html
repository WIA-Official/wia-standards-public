<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 4: Phase 1 - Emotion Data Format - WIA Emotion AI Standard Ebook</title>
</head>
<body>

<p><a href="index.html">ðŸ’— WIA Emotion AI Standard Ebook</a> | Chapter 4 of 8</p>

<hr>

<h1>ðŸ’— Chapter 4: Phase 1 - Emotion Data Format</h1>

<blockquote>
<p><strong>Hongik Ingan (å¼˜ç›Šäººé–“)</strong></p>
<p>"Benefit All Humanity"</p>
<p>A standardized data format is the foundation of interoperability. The WIA Emotion AI data format ensures that emotion data can be shared and processed across any compliant system.</p>
</blockquote>

<hr>

<h2>4.1 Overview</h2>

<h3>4.1.1 Purpose</h3>

<p>Phase 1 defines the JSON-based data format for representing emotion analysis results. This standardized format enables:</p>

<ul>
    <li>Interoperability between different vendors</li>
    <li>Consistent data storage and retrieval</li>
    <li>Easy integration with existing systems</li>
    <li>Clear semantics for all emotion data fields</li>
</ul>

<h3>4.1.2 Design Goals</h3>

<table border="1" cellpadding="10">
    <thead>
        <tr>
            <th>Goal</th>
            <th>Implementation</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Simplicity</td>
            <td>JSON format, clear field names</td>
        </tr>
        <tr>
            <td>Completeness</td>
            <td>Supports all emotion models and modalities</td>
        </tr>
        <tr>
            <td>Extensibility</td>
            <td>Custom fields allowed with prefixes</td>
        </tr>
        <tr>
            <td>Validation</td>
            <td>JSON Schema for automated verification</td>
        </tr>
        <tr>
            <td>Precision</td>
            <td>High-resolution timestamps and values</td>
        </tr>
    </tbody>
</table>

<hr>

<h2>4.2 Base Message Structure</h2>

<h3>4.2.1 Complete Schema</h3>

<pre>
{
    "$schema": "https://wiastandards.com/emotion-ai/v1/schema.json",
    "format": "WIA-EMOTION-AI-v1.0",
    "timestamp": "2025-12-19T10:30:00.000Z",
    "subject_id": "user_12345",
    "session_id": "sess_abc123",
    "modality": "facial",

    "emotions": {
        "primary": {
            "label": "happiness",
            "confidence": 0.87
        },
        "secondary": {
            "label": "surprise",
            "confidence": 0.23
        },
        "all": [
            { "label": "happiness", "confidence": 0.87 },
            { "label": "surprise", "confidence": 0.23 },
            { "label": "neutral", "confidence": 0.15 },
            { "label": "sadness", "confidence": 0.05 },
            { "label": "anger", "confidence": 0.03 },
            { "label": "fear", "confidence": 0.02 },
            { "label": "disgust", "confidence": 0.01 }
        ]
    },

    "dimensions": {
        "valence": 0.72,
        "arousal": 0.45,
        "dominance": 0.55
    },

    "action_units": [
        { "au": "AU6", "intensity": 0.8, "name": "Cheek Raiser" },
        { "au": "AU12", "intensity": 0.9, "name": "Lip Corner Puller" },
        { "au": "AU1", "intensity": 0.3, "name": "Inner Brow Raiser" }
    ],

    "face": {
        "detected": true,
        "bbox": { "x": 120, "y": 80, "width": 200, "height": 250 },
        "landmarks": 68,
        "pose": { "pitch": 5.2, "yaw": -3.1, "roll": 1.2 }
    },

    "metadata": {
        "model_version": "2.1.0",
        "model_name": "WIA-EmotionNet",
        "processing_time_ms": 45,
        "device_id": "cam_001",
        "culture_context": "global"
    }
}
</pre>

<hr>

<h2>4.3 Field Specifications</h2>

<h3>4.3.1 Root Fields</h3>

<table border="1" cellpadding="10">
    <thead>
        <tr>
            <th>Field</th>
            <th>Type</th>
            <th>Required</th>
            <th>Description</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>format</td>
            <td>string</td>
            <td>REQUIRED</td>
            <td>Format identifier: "WIA-EMOTION-AI-v1.0"</td>
        </tr>
        <tr>
            <td>timestamp</td>
            <td>string (ISO 8601)</td>
            <td>REQUIRED</td>
            <td>Analysis timestamp</td>
        </tr>
        <tr>
            <td>subject_id</td>
            <td>string</td>
            <td>OPTIONAL</td>
            <td>Identifier for the subject (anonymized)</td>
        </tr>
        <tr>
            <td>session_id</td>
            <td>string</td>
            <td>OPTIONAL</td>
            <td>Session identifier for grouping</td>
        </tr>
        <tr>
            <td>modality</td>
            <td>string</td>
            <td>REQUIRED</td>
            <td>Input type: facial, voice, text, biosignal, multimodal</td>
        </tr>
    </tbody>
</table>

<h3>4.3.2 Emotions Object</h3>

<table border="1" cellpadding="10">
    <thead>
        <tr>
            <th>Field</th>
            <th>Type</th>
            <th>Required</th>
            <th>Description</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>emotions.primary</td>
            <td>object</td>
            <td>REQUIRED</td>
            <td>Highest confidence emotion</td>
        </tr>
        <tr>
            <td>emotions.primary.label</td>
            <td>string</td>
            <td>REQUIRED</td>
            <td>Emotion label (happiness, sadness, etc.)</td>
        </tr>
        <tr>
            <td>emotions.primary.confidence</td>
            <td>number (0-1)</td>
            <td>REQUIRED</td>
            <td>Confidence score</td>
        </tr>
        <tr>
            <td>emotions.secondary</td>
            <td>object</td>
            <td>OPTIONAL</td>
            <td>Second highest confidence emotion</td>
        </tr>
        <tr>
            <td>emotions.all</td>
            <td>array</td>
            <td>OPTIONAL</td>
            <td>All emotion scores</td>
        </tr>
    </tbody>
</table>

<h3>4.3.3 Valid Emotion Labels</h3>

<pre>
Basic Emotions (required support):
  "happiness"  - Joy, pleasure, contentment
  "sadness"    - Sorrow, grief, melancholy
  "anger"      - Displeasure, frustration, rage
  "fear"       - Apprehension, anxiety, terror
  "disgust"    - Revulsion, aversion
  "surprise"   - Astonishment, amazement
  "neutral"    - No strong emotion detected

Extended Emotions (optional):
  "contempt"   - Scorn, disdain
  "confusion"  - Uncertainty, puzzlement
  "interest"   - Curiosity, engagement
  "boredom"    - Disengagement
  "excitement" - High positive arousal
  "anxiety"    - Worry, unease
</pre>

<h3>4.3.4 Dimensions Object</h3>

<table border="1" cellpadding="10">
    <thead>
        <tr>
            <th>Field</th>
            <th>Type</th>
            <th>Range</th>
            <th>Description</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>dimensions.valence</td>
            <td>number</td>
            <td>-1.0 to +1.0</td>
            <td>Positive/negative feeling</td>
        </tr>
        <tr>
            <td>dimensions.arousal</td>
            <td>number</td>
            <td>-1.0 to +1.0</td>
            <td>Energy/activation level</td>
        </tr>
        <tr>
            <td>dimensions.dominance</td>
            <td>number</td>
            <td>-1.0 to +1.0</td>
            <td>Control/influence (optional)</td>
        </tr>
    </tbody>
</table>

<h3>4.3.5 Action Units Array</h3>

<table border="1" cellpadding="10">
    <thead>
        <tr>
            <th>Field</th>
            <th>Type</th>
            <th>Description</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>action_units[].au</td>
            <td>string</td>
            <td>AU code (AU1, AU2, AU4, etc.)</td>
        </tr>
        <tr>
            <td>action_units[].intensity</td>
            <td>number (0-1)</td>
            <td>Activation intensity</td>
        </tr>
        <tr>
            <td>action_units[].name</td>
            <td>string</td>
            <td>Human-readable name (optional)</td>
        </tr>
    </tbody>
</table>

<hr>

<h2>4.4 Modality-Specific Extensions</h2>

<h3>4.4.1 Facial Modality</h3>

<pre>
{
    "modality": "facial",
    "face": {
        "detected": true,
        "count": 1,
        "bbox": {
            "x": 120,
            "y": 80,
            "width": 200,
            "height": 250
        },
        "landmarks": 68,
        "pose": {
            "pitch": 5.2,
            "yaw": -3.1,
            "roll": 1.2
        },
        "quality": {
            "blur": 0.1,
            "exposure": 0.8,
            "occlusion": 0.05
        }
    },
    "action_units": [
        { "au": "AU6", "intensity": 0.8 },
        { "au": "AU12", "intensity": 0.9 }
    ]
}
</pre>

<h3>4.4.2 Voice Modality</h3>

<pre>
{
    "modality": "voice",
    "voice": {
        "duration_ms": 3500,
        "sample_rate": 44100,
        "features": {
            "pitch_mean": 180.5,
            "pitch_std": 25.3,
            "intensity_mean": 65.2,
            "speech_rate": 4.2,
            "pause_ratio": 0.15
        },
        "language": "en-US",
        "transcript": "I'm really happy about this!"
    }
}
</pre>

<h3>4.4.3 Text Modality</h3>

<pre>
{
    "modality": "text",
    "text": {
        "content": "This product is absolutely amazing!",
        "language": "en",
        "length": 37,
        "sentiment": {
            "polarity": 0.92,
            "subjectivity": 0.85
        },
        "entities": [
            {
                "text": "product",
                "emotion": "happiness",
                "confidence": 0.88
            }
        ],
        "aspects": [
            {
                "aspect": "quality",
                "sentiment": 0.95
            }
        ]
    }
}
</pre>

<h3>4.4.4 Biosignal Modality</h3>

<pre>
{
    "modality": "biosignal",
    "biosignal": {
        "signals": ["ecg", "eda"],
        "duration_ms": 60000,
        "metrics": {
            "heart_rate": {
                "mean": 75,
                "std": 8,
                "hrv_rmssd": 42.5
            },
            "eda": {
                "scl_mean": 3.2,
                "scr_count": 5,
                "scr_amplitude_mean": 0.8
            }
        },
        "derived": {
            "stress_level": 0.35,
            "engagement": 0.72,
            "relaxation": 0.55
        }
    }
}
</pre>

<h3>4.4.5 Multimodal</h3>

<pre>
{
    "modality": "multimodal",
    "modalities_used": ["facial", "voice"],
    "fusion_method": "weighted_average",
    "modality_weights": {
        "facial": 0.6,
        "voice": 0.4
    },
    "modality_results": {
        "facial": {
            "emotions": { "primary": { "label": "happiness", "confidence": 0.85 } },
            "dimensions": { "valence": 0.7, "arousal": 0.5 }
        },
        "voice": {
            "emotions": { "primary": { "label": "happiness", "confidence": 0.78 } },
            "dimensions": { "valence": 0.6, "arousal": 0.6 }
        }
    }
}
</pre>

<hr>

<h2>4.5 Metadata Object</h2>

<table border="1" cellpadding="10">
    <thead>
        <tr>
            <th>Field</th>
            <th>Type</th>
            <th>Description</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>model_version</td>
            <td>string</td>
            <td>Version of the analysis model</td>
        </tr>
        <tr>
            <td>model_name</td>
            <td>string</td>
            <td>Name of the model used</td>
        </tr>
        <tr>
            <td>processing_time_ms</td>
            <td>integer</td>
            <td>Time taken to process</td>
        </tr>
        <tr>
            <td>device_id</td>
            <td>string</td>
            <td>Identifier for input device</td>
        </tr>
        <tr>
            <td>culture_context</td>
            <td>string</td>
            <td>Cultural context for interpretation</td>
        </tr>
        <tr>
            <td>wia_certified</td>
            <td>boolean</td>
            <td>Whether model is WIA certified</td>
        </tr>
    </tbody>
</table>

<hr>

<h2>4.6 Complete Example</h2>

<pre>
{
    "format": "WIA-EMOTION-AI-v1.0",
    "timestamp": "2025-12-19T10:30:00.123Z",
    "subject_id": "user_12345",
    "session_id": "sess_20251219_001",
    "modality": "facial",

    "emotions": {
        "primary": {
            "label": "happiness",
            "confidence": 0.87
        },
        "secondary": {
            "label": "surprise",
            "confidence": 0.23
        },
        "all": [
            { "label": "happiness", "confidence": 0.87 },
            { "label": "surprise", "confidence": 0.23 },
            { "label": "neutral", "confidence": 0.15 },
            { "label": "sadness", "confidence": 0.05 },
            { "label": "anger", "confidence": 0.03 },
            { "label": "fear", "confidence": 0.02 },
            { "label": "disgust", "confidence": 0.01 }
        ]
    },

    "dimensions": {
        "valence": 0.72,
        "arousal": 0.45
    },

    "action_units": [
        { "au": "AU6", "intensity": 0.8, "name": "Cheek Raiser" },
        { "au": "AU12", "intensity": 0.9, "name": "Lip Corner Puller" },
        { "au": "AU1", "intensity": 0.3, "name": "Inner Brow Raiser" },
        { "au": "AU2", "intensity": 0.25, "name": "Outer Brow Raiser" },
        { "au": "AU25", "intensity": 0.4, "name": "Lips Part" }
    ],

    "face": {
        "detected": true,
        "count": 1,
        "bbox": { "x": 120, "y": 80, "width": 200, "height": 250 },
        "landmarks": 68,
        "pose": { "pitch": 5.2, "yaw": -3.1, "roll": 1.2 },
        "quality": { "blur": 0.1, "exposure": 0.8, "occlusion": 0.05 }
    },

    "metadata": {
        "model_version": "2.1.0",
        "model_name": "WIA-EmotionNet-v2",
        "processing_time_ms": 45,
        "device_id": "webcam_001",
        "culture_context": "western",
        "wia_certified": true,
        "certification_level": 2
    }
}
</pre>

<hr>

<h2>4.7 JSON Schema Definition</h2>

<pre>
{
    "$schema": "http://json-schema.org/draft-07/schema#",
    "$id": "https://wiastandards.com/emotion-ai/v1/schema.json",
    "title": "WIA Emotion AI Data Format",
    "type": "object",
    "required": ["format", "timestamp", "modality", "emotions"],
    "properties": {
        "format": {
            "type": "string",
            "pattern": "^WIA-EMOTION-AI-v[0-9]+\\.[0-9]+$"
        },
        "timestamp": {
            "type": "string",
            "format": "date-time"
        },
        "modality": {
            "type": "string",
            "enum": ["facial", "voice", "text", "biosignal", "multimodal"]
        },
        "emotions": {
            "type": "object",
            "required": ["primary"],
            "properties": {
                "primary": { "$ref": "#/definitions/emotionScore" },
                "secondary": { "$ref": "#/definitions/emotionScore" },
                "all": {
                    "type": "array",
                    "items": { "$ref": "#/definitions/emotionScore" }
                }
            }
        },
        "dimensions": {
            "type": "object",
            "properties": {
                "valence": { "type": "number", "minimum": -1, "maximum": 1 },
                "arousal": { "type": "number", "minimum": -1, "maximum": 1 },
                "dominance": { "type": "number", "minimum": -1, "maximum": 1 }
            }
        },
        "action_units": {
            "type": "array",
            "items": { "$ref": "#/definitions/actionUnit" }
        }
    },
    "definitions": {
        "emotionScore": {
            "type": "object",
            "required": ["label", "confidence"],
            "properties": {
                "label": { "type": "string" },
                "confidence": { "type": "number", "minimum": 0, "maximum": 1 }
            }
        },
        "actionUnit": {
            "type": "object",
            "required": ["au", "intensity"],
            "properties": {
                "au": { "type": "string", "pattern": "^AU[0-9]+$" },
                "intensity": { "type": "number", "minimum": 0, "maximum": 1 },
                "name": { "type": "string" }
            }
        }
    }
}
</pre>

<hr>

<h2>4.8 Chapter Summary</h2>

<p>[OK] <strong>Key Takeaways:</strong></p>

<ol>
    <li><strong>JSON Format:</strong> All emotion data uses JSON with defined schema</li>
    <li><strong>Required Fields:</strong> format, timestamp, modality, emotions</li>
    <li><strong>Emotion Models:</strong> Supports both discrete labels and V-A dimensions</li>
    <li><strong>Action Units:</strong> FACS AU encoding with 0-1 intensity</li>
    <li><strong>Modality Extensions:</strong> Specific fields for face, voice, text, biosignal</li>
    <li><strong>Multimodal:</strong> Fusion results with modality weights</li>
    <li><strong>Validation:</strong> JSON Schema enables automated verification</li>
</ol>

<hr>

<h2>4.9 Looking Ahead</h2>

<p>In Chapter 5, we will explore Phase 2: API Interface, covering REST API endpoints for emotion analysis across all modalities.</p>

<hr>

<p><strong>Chapter 4 Complete</strong> | Approximate pages: 16</p>

<p><a href="chapter-05.html">Next: Chapter 5 - Phase 2: API Interface</a></p>

<hr>

<p><strong>WIA - World Certification Industry Association</strong></p>
<p>Hongik Ingan - Benefit All Humanity</p>
<p><a href="https://wiastandards.com">https://wiastandards.com</a></p>

</body>
</html>
