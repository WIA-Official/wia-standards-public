<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>제1장: 감정 AI 소개 - WIA 감정 AI 표준 전자책</title>
</head>
<body>

<p><a href="index.html">💗 WIA 감정 AI 표준 전자책</a> | 제1장 (총 8장)</p>

<hr>

<h1>💗 제1장: 감정 AI 소개</h1>

<blockquote>
<p><strong>홍익인간 (弘益人間)</strong></p>
<p>"널리 인간을 이롭게 하라"</p>
<p>WIA 감정 AI 표준은 인간의 감정을 이해하는 것이 진정으로 인류에 봉사하는 기술을 만드는 데 근본적이라는 철학에 기반합니다.</p>
</blockquote>

<hr>

<h2>1.1 감정 AI(정서 컴퓨팅)란 무엇인가?</h2>

<p><strong>감정 AI(Emotion AI)</strong>, 또는 <strong>정서 컴퓨팅(Affective Computing)</strong>은 인공지능, 컴퓨터 과학, 심리학, 인지과학을 결합하여 인간의 감정을 인식, 해석, 처리, 시뮬레이션할 수 있는 시스템을 개발하는 다학제적 분야입니다.</p>

<p>[i] <strong>정의:</strong> 정서 컴퓨팅은 인간의 정서(감정, 기분, 태도)를 인식, 해석, 처리, 시뮬레이션할 수 있는 시스템과 장치의 연구 및 개발입니다.</p>

<h3>1.1.1 기원: Rosalind Picard</h3>

<p>정서 컴퓨팅 분야는 1995년 MIT 미디어랩의 <strong>Rosalind Picard 박사</strong>에 의해 설립되었습니다. 그녀의 선구적인 논문 "Affective Computing"은 수십억 달러 규모의 산업의 기반이 되었습니다.</p>

<table border="1" cellpadding="10">
    <tr>
        <td><strong>창시자</strong></td>
        <td>Rosalind Picard, Sc.D.</td>
    </tr>
    <tr>
        <td><strong>기관</strong></td>
        <td>MIT 미디어랩</td>
    </tr>
    <tr>
        <td><strong>년도</strong></td>
        <td>1995</td>
    </tr>
    <tr>
        <td><strong>주요 출판물</strong></td>
        <td>"Affective Computing" (1997년 서적)</td>
    </tr>
    <tr>
        <td><strong>핵심 논지</strong></td>
        <td>감정은 인간 지능과 의사결정에 필수적</td>
    </tr>
</table>

<h3>1.1.2 컴퓨팅에서 감정이 중요한 이유</h3>

<p>Picard의 획기적인 통찰은 감정이 이성적 사고와 분리된 것이 아니라 그것에 필수적이라는 것이었습니다. 특히 Antonio Damasio의 신경과학 연구는 뇌의 감정 중추가 손상된 사람들이 간단한 결정을 내리는 데도 어려움을 겪는다는 것을 보여주었습니다.</p>

<p><strong>핵심 통찰:</strong></p>
<ul>
    <li>감정은 주의력과 기억을 유도</li>
    <li>감정 반응은 인지 처리보다 빠름</li>
    <li>인간-컴퓨터 상호작용은 본질적으로 감정적</li>
    <li>감정을 이해하는 기계가 인간을 더 잘 서비스할 수 있음</li>
</ul>

<hr>

<h2>1.2 시장 규모 및 성장</h2>

<p>감정 AI 시장은 폭발적인 성장을 경험했으며 계속해서 빠르게 확장될 것으로 예상됩니다:</p>

<table border="1" cellpadding="10">
    <thead>
        <tr>
            <th>연도</th>
            <th>시장 규모 (USD)</th>
            <th>성장률</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>2020</td>
            <td>216억 달러</td>
            <td>-</td>
        </tr>
        <tr>
            <td>2021</td>
            <td>248억 달러</td>
            <td>14.8%</td>
        </tr>
        <tr>
            <td>2022</td>
            <td>285억 달러</td>
            <td>14.9%</td>
        </tr>
        <tr>
            <td>2023</td>
            <td>327억 달러</td>
            <td>14.7%</td>
        </tr>
        <tr>
            <td>2026 (예상)</td>
            <td>371억 달러</td>
            <td>CAGR 13.5%</td>
        </tr>
    </tbody>
</table>

<h3>1.2.1 시장 부문</h3>

<p>감정 AI 시장은 여러 산업 분야에 걸쳐 있습니다:</p>

<ul>
    <li><strong>헬스케어 (28%)</strong> - 정신건강 모니터링, 환자 케어</li>
    <li><strong>소매/마케팅 (24%)</strong> - 소비자 연구, 광고 효과</li>
    <li><strong>자동차 (18%)</strong> - 운전자 모니터링 시스템</li>
    <li><strong>미디어/엔터테인먼트 (15%)</strong> - 콘텐츠 최적화, 게임</li>
    <li><strong>교육 (10%)</strong> - 적응형 학습, 학생 참여</li>
    <li><strong>기타 (5%)</strong> - 보안, 접근성, 고객 서비스</li>
</ul>

<hr>

<h2>1.3 감정 분류 모델</h2>

<h3>1.3.1 에크만의 이산 모델 (6가지 기본 감정)</h3>

<p>Paul Ekman 박사의 1970년대 연구는 모든 인간 문화에서 인식되는 6가지 보편적 감정을 식별했습니다:</p>

<table border="1" cellpadding="10">
    <thead>
        <tr>
            <th>감정</th>
            <th>설명</th>
            <th>얼굴 특징</th>
            <th>보편적 인식률</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td><strong>😊 행복 (Happiness)</strong></td>
            <td>기쁨의 긍정적 감정 상태</td>
            <td>볼 올라감, 까마귀 발자국, 입꼬리 올라감</td>
            <td>93%</td>
        </tr>
        <tr>
            <td><strong>😢 슬픔 (Sadness)</strong></td>
            <td>감정적 고통과 슬픔</td>
            <td>안쪽 눈썹 올라감, 입꼬리 내려감</td>
            <td>84%</td>
        </tr>
        <tr>
            <td><strong>😠 분노 (Anger)</strong></td>
            <td>강한 불쾌 반응</td>
            <td>눈썹 내려감, 턱 긴장, 눈 좁아짐</td>
            <td>90%</td>
        </tr>
        <tr>
            <td><strong>😨 공포 (Fear)</strong></td>
            <td>인지된 위협에 대한 반응</td>
            <td>눈 크게 뜸, 눈썹 올라감, 입 벌어짐</td>
            <td>85%</td>
        </tr>
        <tr>
            <td><strong>🤢 혐오 (Disgust)</strong></td>
            <td>역겨움 또는 강한 비난</td>
            <td>코 주름, 윗입술 올라감</td>
            <td>88%</td>
        </tr>
        <tr>
            <td><strong>😮 놀람 (Surprise)</strong></td>
            <td>예상치 못한 것에 대한 짧은 감정 반응</td>
            <td>눈썹 올라감, 눈 크게 뜸, 턱 떨어짐</td>
            <td>81%</td>
        </tr>
    </tbody>
</table>

<p>[i] <strong>참고:</strong> WIA 감정 AI 표준은 강한 감정 표현이 없음을 나타내는 <strong>중립(Neutral)</strong>도 7번째 카테고리로 포함합니다.</p>

<h3>1.3.2 차원 모델 (Valence-Arousal)</h3>

<p>James Russell이 개발한 차원 모델은 감정을 연속적인 2차원 공간에서 나타냅니다:</p>

<pre>
                    고각성 (High Arousal)
                         |
                   흥분   |  긴장
                         |
    부정 ────────+───────+───────+──── 긍정
    Valence     |       |       |     Valence
                   지루함  |  만족
                         |
                    저각성 (Low Arousal)

사분면 매핑:
  고 Valence + 고 Arousal = 흥분, 행복, 열광
  고 Valence + 저 Arousal = 평온, 편안, 고요
  저 Valence + 고 Arousal = 분노, 두려움, 스트레스
  저 Valence + 저 Arousal = 슬픔, 우울, 지루함
</pre>

<p><strong>Valence:</strong> -1(부정)에서 +1(긍정) 범위, 감정의 유쾌함을 나타냅니다.</p>
<p><strong>Arousal:</strong> -1(저각성)에서 +1(고각성) 범위, 강도 또는 에너지 수준을 나타냅니다.</p>

<hr>

<h2>1.4 FACS - 얼굴 행동 코딩 시스템</h2>

<h3>1.4.1 역사와 개발</h3>

<p>얼굴 행동 코딩 시스템(FACS)은 1978년 Paul Ekman과 Wallace V. Friesen에 의해 개발되었습니다. 이는 액션 유닛(AU)을 통해 얼굴 움직임을 체계적으로 설명하는 방법을 제공합니다.</p>

<h3>1.4.2 액션 유닛</h3>

<p>액션 유닛은 특정 얼굴 근육의 수축 또는 이완을 나타냅니다. 각 AU에는 번호와 이름이 지정됩니다:</p>

<table border="1" cellpadding="10">
    <thead>
        <tr>
            <th>AU</th>
            <th>FACS 이름</th>
            <th>근육</th>
            <th>설명</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>AU1</td>
            <td>안쪽 눈썹 올림 (Inner Brow Raiser)</td>
            <td>전두근 (내측부)</td>
            <td>눈썹 안쪽 부분 올림</td>
        </tr>
        <tr>
            <td>AU2</td>
            <td>바깥쪽 눈썹 올림 (Outer Brow Raiser)</td>
            <td>전두근 (외측부)</td>
            <td>눈썹 바깥쪽 부분 올림</td>
        </tr>
        <tr>
            <td>AU4</td>
            <td>눈썹 내림 (Brow Lowerer)</td>
            <td>추미근, 비근억제근</td>
            <td>눈썹을 내리고 모음</td>
        </tr>
        <tr>
            <td>AU6</td>
            <td>볼 올림 (Cheek Raiser)</td>
            <td>안륜근 (안와부)</td>
            <td>볼을 올리고 까마귀발 생성</td>
        </tr>
        <tr>
            <td>AU12</td>
            <td>입꼬리 올림 (Lip Corner Puller)</td>
            <td>대관골근</td>
            <td>입꼬리를 위로 당김 (미소)</td>
        </tr>
        <tr>
            <td>AU15</td>
            <td>입꼬리 내림 (Lip Corner Depressor)</td>
            <td>구각하제근</td>
            <td>입꼬리를 아래로 당김 (찡그림)</td>
        </tr>
    </tbody>
</table>

<h3>1.4.3 감정-AU 매핑</h3>

<p>각 기본 감정은 액션 유닛의 조합으로 설명될 수 있습니다:</p>

<table border="1" cellpadding="10">
    <thead>
        <tr>
            <th>감정</th>
            <th>일반적인 AU 조합</th>
            <th>설명</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>행복</td>
            <td>AU6 + AU12</td>
            <td>볼 올림 + 입꼬리 올림 (뒤셴 미소)</td>
        </tr>
        <tr>
            <td>슬픔</td>
            <td>AU1 + AU4 + AU15</td>
            <td>안쪽 눈썹 올림 + 눈썹 내림 + 입꼬리 내림</td>
        </tr>
        <tr>
            <td>분노</td>
            <td>AU4 + AU5 + AU7 + AU23</td>
            <td>눈썹 내림 + 위 눈꺼풀 올림 + 눈꺼풀 조임 + 입술 조임</td>
        </tr>
        <tr>
            <td>공포</td>
            <td>AU1 + AU2 + AU4 + AU5 + AU20 + AU26</td>
            <td>눈썹 올림 + 눈썹 내림 + 위 눈꺼풀 올림 + 입술 펴기 + 턱 떨어뜨림</td>
        </tr>
    </tbody>
</table>

<hr>

<h2>1.5 입력 모달리티</h2>

<p>감정 AI 시스템은 여러 입력 채널을 통해 감정을 분석할 수 있습니다:</p>

<h3>1.5.1 표정 분석</h3>

<ul>
    <li><strong>입력:</strong> 카메라/비디오 피드</li>
    <li><strong>기술:</strong> 컴퓨터 비전, CNN, 딥러닝</li>
    <li><strong>출력:</strong> 감정 레이블, AU 강도, V-A 좌표</li>
    <li><strong>정확도:</strong> 정면 얼굴에서 85-95%</li>
</ul>

<h3>1.5.2 음성/발화 분석</h3>

<ul>
    <li><strong>입력:</strong> 오디오 신호</li>
    <li><strong>기술:</strong> 음성 인식, 음향 특징 추출</li>
    <li><strong>특징:</strong> 피치, 강도, 발화 속도, 음질</li>
    <li><strong>정확도:</strong> 70-85%</li>
</ul>

<h3>1.5.3 텍스트 감성 분석</h3>

<ul>
    <li><strong>입력:</strong> 텍스트 (채팅, 소셜 미디어, 리뷰)</li>
    <li><strong>기술:</strong> NLP, 트랜스포머 모델, BERT</li>
    <li><strong>출력:</strong> 감성 극성, 감정 카테고리</li>
    <li><strong>정확도:</strong> 80-90%</li>
</ul>

<h3>1.5.4 생체신호 분석</h3>

<ul>
    <li><strong>입력:</strong> 생리학적 센서 (ECG, EDA, EEG)</li>
    <li><strong>신호:</strong>
        <ul>
            <li>심박 변이도 (HRV)</li>
            <li>피부 전도 활동 (EDA/GSR)</li>
            <li>뇌전도 (EEG)</li>
            <li>호흡률</li>
        </ul>
    </li>
    <li><strong>정확도:</strong> 75-85%</li>
</ul>

<hr>

<h2>1.6 주요 활용 사례</h2>

<h3>1.6.1 헬스케어</h3>

<ul>
    <li><strong>정신건강 모니터링:</strong> 우울증, 불안, PTSD 증상 추적</li>
    <li><strong>원격의료:</strong> 화상 상담 중 환자 감정 상태 평가</li>
    <li><strong>자폐 연구:</strong> 감정 표현 패턴 분석</li>
    <li><strong>통증 평가:</strong> 비언어적 환자의 통증 감지</li>
</ul>

<h3>1.6.2 마케팅 및 소비자 연구</h3>

<ul>
    <li><strong>광고 테스트:</strong> 광고에 대한 감정 반응 측정</li>
    <li><strong>제품 디자인:</strong> 프로토타입에 대한 사용자 반응 평가</li>
    <li><strong>브랜드 인식:</strong> 소비자 감성 분석</li>
</ul>

<h3>1.6.3 교육</h3>

<ul>
    <li><strong>참여도 감지:</strong> 혼란스럽거나 지루한 학생 식별</li>
    <li><strong>적응형 학습:</strong> 감정 상태에 따라 콘텐츠 조정</li>
    <li><strong>온라인 감독:</strong> 시험 응시 스트레스 수준 모니터링</li>
</ul>

<h3>1.6.4 자동차</h3>

<ul>
    <li><strong>운전자 모니터링:</strong> 졸음, 주의 산만, 분노 감지</li>
    <li><strong>안전 경고:</strong> 경고 또는 개입 트리거</li>
    <li><strong>자율주행:</strong> 승객 편안함 이해</li>
</ul>

<hr>

<h2>1.7 WIA 철학: 홍익인간</h2>

<blockquote>
<p><strong>弘益人間 (홍익인간)</strong></p>
<p>"널리 인간을 이롭게 하라"</p>
<p>이 고대 한국 철학이 WIA 감정 AI 표준을 안내합니다. 우리는 다음을 믿습니다:</p>
<ul>
    <li>감정 AI는 윤리적이고 프라이버시를 존중해야 함</li>
    <li>표준은 모든 사람에게 개방적이고 접근 가능해야 함</li>
    <li>기술은 인간 복지에 봉사해야 함</li>
    <li>감정 표현의 문화적 다양성이 존중되어야 함</li>
</ul>
</blockquote>

<hr>

<h2>1.8 장 요약</h2>

<p>[OK] <strong>핵심 내용:</strong></p>

<ol>
    <li><strong>정의:</strong> 감정 AI(정서 컴퓨팅)는 기계가 인간의 감정을 인식하고 반응할 수 있게 함</li>
    <li><strong>기원:</strong> 1995년 MIT 미디어랩의 Rosalind Picard에 의해 창시</li>
    <li><strong>시장:</strong> 2026년까지 371억 달러 도달 예상</li>
    <li><strong>모델:</strong> 에크만의 이산 모델(6가지 감정)과 차원 모델(Valence-Arousal)</li>
    <li><strong>FACS:</strong> 액션 유닛을 사용한 표정의 체계적 코딩</li>
    <li><strong>모달리티:</strong> 얼굴, 음성, 텍스트, 생체신호</li>
    <li><strong>응용:</strong> 헬스케어, 마케팅, 교육, 자동차, 게임</li>
</ol>

<hr>

<h2>1.9 복습 문제</h2>

<ol>
    <li>정서 컴퓨팅 분야를 창시한 사람과 시기는?</li>
    <li>Paul Ekman이 식별한 6가지 기본 감정을 나열하세요.</li>
    <li>Valence-Arousal 모델의 두 차원은 무엇입니까?</li>
    <li>FACS와 액션 유닛은 무엇입니까?</li>
    <li>감정 인식을 위한 4가지 입력 모달리티를 나열하세요.</li>
    <li>헬스케어에서 감정 AI의 3가지 활용 사례를 설명하세요.</li>
</ol>

<hr>

<h2>1.10 다음 장 미리보기</h2>

<p>제2장에서는 문화적 차이, 프라이버시 우려, 정확도 한계, WIA 감정 AI 표준이 해결하는 표준화의 필요성을 포함하여 감정 AI의 현재 과제를 탐구합니다.</p>

<hr>

<p><strong>제1장 완료</strong> | 예상 페이지: 16</p>

<p><a href="chapter-02.html">다음: 제2장 - 현재 과제</a></p>

<hr>

<p><strong>WIA - 세계인증산업협회</strong></p>
<p>홍익인간 - 널리 인간을 이롭게</p>
<p><a href="https://wiastandards.com">https://wiastandards.com</a></p>

</body>
</html>
