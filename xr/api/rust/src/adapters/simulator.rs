//! XR Simulator Adapter
//!
//! Simulates XR device behavior for testing and development.

use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;

use crate::types::*;
use crate::core::{AdaptationType, AdaptationStatus};

/// Simulated XR environment state
#[derive(Debug, Clone)]
pub struct SimulatorState {
    pub head_position: Vector3,
    pub head_rotation: Quaternion,
    pub left_hand_position: Option<Vector3>,
    pub right_hand_position: Option<Vector3>,
    pub eye_gaze_target: Option<Vector3>,
    pub voice_input: Option<String>,
    pub active_ui_element: Option<String>,
    pub current_scene: String,
    pub is_in_safe_space: bool,
}

impl Default for SimulatorState {
    fn default() -> Self {
        Self {
            head_position: Vector3 { x: 0.0, y: 1.6, z: 0.0 },
            head_rotation: Quaternion { x: 0.0, y: 0.0, z: 0.0, w: 1.0 },
            left_hand_position: None,
            right_hand_position: None,
            eye_gaze_target: None,
            voice_input: None,
            active_ui_element: None,
            current_scene: "default".into(),
            is_in_safe_space: false,
        }
    }
}

/// 3D vector
#[derive(Debug, Clone, Copy, Default)]
pub struct Vector3 {
    pub x: f32,
    pub y: f32,
    pub z: f32,
}

/// Quaternion for rotation
#[derive(Debug, Clone, Copy)]
pub struct Quaternion {
    pub x: f32,
    pub y: f32,
    pub z: f32,
    pub w: f32,
}

impl Default for Quaternion {
    fn default() -> Self {
        Self { x: 0.0, y: 0.0, z: 0.0, w: 1.0 }
    }
}

/// XR Simulator for testing accessibility features
pub struct XRSimulator {
    state: Arc<RwLock<SimulatorState>>,
    device: XRDeviceCapabilities,
    profile: Option<XRAccessibilityProfile>,
    active_adaptations: Arc<RwLock<HashMap<AdaptationType, AdaptationStatus>>>,
    events: Arc<RwLock<Vec<SimulatorEvent>>>,
}

/// Events generated by the simulator
#[derive(Debug, Clone)]
pub enum SimulatorEvent {
    HeadMoved { position: Vector3, rotation: Quaternion },
    HandMoved { hand: Hand, position: Vector3 },
    EyeGazeChanged { target: Vector3 },
    VoiceCommand { text: String },
    UIElementFocused { element_id: String },
    SceneChanged { scene_id: String },
    AdaptationTriggered { adaptation: AdaptationType },
    SafeSpaceToggled { entered: bool },
}

#[derive(Debug, Clone, Copy)]
pub enum Hand {
    Left,
    Right,
}

impl XRSimulator {
    /// Create a new simulator with default device
    pub fn new() -> Self {
        Self::with_device(Self::create_default_device())
    }

    /// Create a simulator with specific device capabilities
    pub fn with_device(device: XRDeviceCapabilities) -> Self {
        Self {
            state: Arc::new(RwLock::new(SimulatorState::default())),
            device,
            profile: None,
            active_adaptations: Arc::new(RwLock::new(HashMap::new())),
            events: Arc::new(RwLock::new(Vec::new())),
        }
    }

    /// Create a default simulated device (Quest 3-like)
    pub fn create_default_device() -> XRDeviceCapabilities {
        XRDeviceCapabilities {
            device_id: "simulator-001".into(),
            device_name: "WIA XR Simulator".into(),
            manufacturer: "WIA".into(),
            model: "Simulator v1".into(),
            firmware_version: "1.0.0".into(),
            display: DisplayCapabilities {
                display_type: DisplayType::Lcd,
                resolution_per_eye: Resolution { width: 2064, height: 2208 },
                refresh_rates: vec![72.0, 90.0, 120.0],
                field_of_view: FieldOfViewCaps { horizontal: 110.0, vertical: 96.0 },
                supports_passthrough: true,
                passthrough_color: true,
                supports_foveated_rendering: true,
            },
            audio: AudioCapabilities {
                has_speakers: true,
                speaker_type: Some(SpeakerType::Integrated),
                has_microphone: true,
                supports_spatial_audio: true,
                supports_bone_conduction: false,
            },
            input: InputCapabilities {
                controller_type: ControllerType::SixDof,
                has_eye_tracking: true,
                has_hand_tracking: true,
                has_face_tracking: true,
                has_body_tracking: false,
                voice_control: true,
                controller_features: Some(ControllerFeatures {
                    has_haptics: true,
                    has_triggers: true,
                    has_grip: true,
                    has_thumbstick: true,
                    has_touchpad: false,
                    button_count: 8,
                }),
            },
            haptics: HapticCapabilities {
                controller_haptics: true,
                haptic_fidelity: HapticFidelity::Hd,
                supports_external_haptics: true,
            },
            built_in_accessibility: BuiltInAccessibility {
                screen_reader: true,
                magnification: true,
                color_correction: true,
                caption_support: true,
                voice_control: true,
                one_handed_mode: true,
                seated_mode: true,
            },
            wia_compatibility: WIACompatibility {
                exoskeleton_compatible: true,
                bionic_eye_compatible: true,
                voice_sign_compatible: true,
                protocol_version: "1.0.0".into(),
            },
        }
    }

    /// Load an accessibility profile
    pub async fn load_profile(&mut self, profile: XRAccessibilityProfile) {
        self.profile = Some(profile);
        self.apply_profile_settings().await;
    }

    /// Get the simulated device capabilities
    pub fn get_device(&self) -> &XRDeviceCapabilities {
        &self.device
    }

    /// Get current simulator state
    pub async fn get_state(&self) -> SimulatorState {
        self.state.read().await.clone()
    }

    /// Simulate head movement
    pub async fn move_head(&self, position: Vector3, rotation: Quaternion) {
        let mut state = self.state.write().await;
        state.head_position = position;
        state.head_rotation = rotation;

        self.record_event(SimulatorEvent::HeadMoved { position, rotation }).await;
    }

    /// Simulate hand movement
    pub async fn move_hand(&self, hand: Hand, position: Vector3) {
        let mut state = self.state.write().await;
        match hand {
            Hand::Left => state.left_hand_position = Some(position),
            Hand::Right => state.right_hand_position = Some(position),
        }

        self.record_event(SimulatorEvent::HandMoved { hand, position }).await;
    }

    /// Simulate eye gaze
    pub async fn set_eye_gaze(&self, target: Vector3) {
        let mut state = self.state.write().await;
        state.eye_gaze_target = Some(target);

        self.record_event(SimulatorEvent::EyeGazeChanged { target }).await;
    }

    /// Simulate voice command
    pub async fn speak(&self, text: impl Into<String>) {
        let text = text.into();
        let mut state = self.state.write().await;
        state.voice_input = Some(text.clone());

        self.record_event(SimulatorEvent::VoiceCommand { text }).await;
    }

    /// Simulate UI element focus
    pub async fn focus_element(&self, element_id: impl Into<String>) {
        let element_id = element_id.into();
        let mut state = self.state.write().await;
        state.active_ui_element = Some(element_id.clone());

        self.record_event(SimulatorEvent::UIElementFocused { element_id }).await;
    }

    /// Change scene
    pub async fn change_scene(&self, scene_id: impl Into<String>) {
        let scene_id = scene_id.into();
        let mut state = self.state.write().await;
        state.current_scene = scene_id.clone();

        self.record_event(SimulatorEvent::SceneChanged { scene_id }).await;
    }

    /// Toggle safe space
    pub async fn toggle_safe_space(&self, enter: bool) {
        let mut state = self.state.write().await;
        state.is_in_safe_space = enter;

        self.record_event(SimulatorEvent::SafeSpaceToggled { entered: enter }).await;
    }

    /// Trigger an adaptation
    pub async fn trigger_adaptation(&self, adaptation: AdaptationType) {
        let mut adaptations = self.active_adaptations.write().await;
        adaptations.insert(adaptation.clone(), AdaptationStatus::Active);

        self.record_event(SimulatorEvent::AdaptationTriggered { adaptation }).await;
    }

    /// Get active adaptations
    pub async fn get_active_adaptations(&self) -> HashMap<AdaptationType, AdaptationStatus> {
        self.active_adaptations.read().await.clone()
    }

    /// Get recorded events
    pub async fn get_events(&self) -> Vec<SimulatorEvent> {
        self.events.read().await.clone()
    }

    /// Clear recorded events
    pub async fn clear_events(&self) {
        self.events.write().await.clear();
    }

    /// Check if feature is available
    pub fn has_feature(&self, feature: &str) -> bool {
        match feature {
            "eye_tracking" => self.device.input.has_eye_tracking,
            "hand_tracking" => self.device.input.has_hand_tracking,
            "voice_control" => self.device.input.voice_control,
            "haptics" => self.device.haptics.controller_haptics,
            "passthrough" => self.device.display.supports_passthrough,
            "spatial_audio" => self.device.audio.supports_spatial_audio,
            "screen_reader" => self.device.built_in_accessibility.screen_reader,
            "magnification" => self.device.built_in_accessibility.magnification,
            "captions" => self.device.built_in_accessibility.caption_support,
            _ => false,
        }
    }

    async fn apply_profile_settings(&self) {
        if let Some(ref profile) = self.profile {
            let mut adaptations = self.active_adaptations.write().await;

            // Apply based on disability profile
            if let Some(ref visual) = profile.disabilities.visual {
                if visual.level == VisualLevel::TotallyBlind || visual.level == VisualLevel::LegallyBlind {
                    adaptations.insert(AdaptationType::ScreenReader, AdaptationStatus::Active);
                    adaptations.insert(AdaptationType::AudioDescription, AdaptationStatus::Active);
                }
                if visual.color_vision != ColorVision::Normal {
                    adaptations.insert(AdaptationType::ColorCorrection, AdaptationStatus::Active);
                }
            }

            if let Some(ref auditory) = profile.disabilities.auditory {
                if auditory.level == AuditoryLevel::Deaf || auditory.level == AuditoryLevel::Deafblind {
                    adaptations.insert(AdaptationType::Captions, AdaptationStatus::Active);
                    adaptations.insert(AdaptationType::VisualSoundIndicators, AdaptationStatus::Active);
                }
            }

            // Apply based on output preferences
            if profile.output.captions.enabled {
                adaptations.insert(AdaptationType::Captions, AdaptationStatus::Active);
            }

            if profile.output.audio_description.enabled {
                adaptations.insert(AdaptationType::AudioDescription, AdaptationStatus::Active);
            }

            if profile.output.screen_reader.enabled {
                adaptations.insert(AdaptationType::ScreenReader, AdaptationStatus::Active);
            }

            // Apply motion comfort
            if profile.comfort.motion.vignette_enabled {
                adaptations.insert(AdaptationType::ComfortVignette, AdaptationStatus::Active);
            }
        }
    }

    async fn record_event(&self, event: SimulatorEvent) {
        self.events.write().await.push(event);
    }
}

impl Default for XRSimulator {
    fn default() -> Self {
        Self::new()
    }
}

/// Simulated caption generator
pub struct SimulatedCaptionGenerator {
    delay_ms: u64,
}

impl SimulatedCaptionGenerator {
    pub fn new() -> Self {
        Self { delay_ms: 100 }
    }

    pub fn with_delay(delay_ms: u64) -> Self {
        Self { delay_ms }
    }

    pub async fn generate_caption(&self, audio_text: &str) -> Caption {
        tokio::time::sleep(tokio::time::Duration::from_millis(self.delay_ms)).await;

        Caption {
            text: audio_text.to_string(),
            speaker: Some("Unknown".to_string()),
            start_time: chrono::Utc::now(),
            duration_ms: 3000,
            confidence: 0.95,
        }
    }
}

impl Default for SimulatedCaptionGenerator {
    fn default() -> Self {
        Self::new()
    }
}

/// Caption data
#[derive(Debug, Clone)]
pub struct Caption {
    pub text: String,
    pub speaker: Option<String>,
    pub start_time: chrono::DateTime<chrono::Utc>,
    pub duration_ms: u64,
    pub confidence: f32,
}

/// Simulated audio description generator
pub struct SimulatedAudioDescriptor {
    detail_level: DetailLevel,
}

impl SimulatedAudioDescriptor {
    pub fn new(detail_level: DetailLevel) -> Self {
        Self { detail_level }
    }

    pub async fn describe_scene(&self, scene_name: &str) -> AudioDescription {
        let description = match self.detail_level {
            DetailLevel::Minimal => format!("Scene: {}", scene_name),
            DetailLevel::Standard => format!("You are now in {}. The environment appears calm.", scene_name),
            DetailLevel::Detailed => format!(
                "You have entered {}. The area is well-lit with ambient lighting. \
                 Interactive elements are visible ahead. The atmosphere is welcoming.",
                scene_name
            ),
        };

        AudioDescription {
            text: description,
            category: DescriptionCategory::Scene,
            priority: DescriptionPriority::Normal,
        }
    }

    pub async fn describe_action(&self, action: &str) -> AudioDescription {
        AudioDescription {
            text: format!("Action: {}", action),
            category: DescriptionCategory::Action,
            priority: DescriptionPriority::High,
        }
    }
}

/// Audio description data
#[derive(Debug, Clone)]
pub struct AudioDescription {
    pub text: String,
    pub category: DescriptionCategory,
    pub priority: DescriptionPriority,
}

#[derive(Debug, Clone, Copy)]
pub enum DescriptionCategory {
    Scene,
    Action,
    UI,
    Object,
    Character,
}

#[derive(Debug, Clone, Copy)]
pub enum DescriptionPriority {
    Low,
    Normal,
    High,
    Critical,
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_simulator_creation() {
        let sim = XRSimulator::new();
        assert_eq!(sim.get_device().device_name, "WIA XR Simulator");
    }

    #[tokio::test]
    async fn test_head_movement() {
        let sim = XRSimulator::new();
        let new_pos = Vector3 { x: 1.0, y: 1.5, z: 0.5 };
        let new_rot = Quaternion { x: 0.1, y: 0.0, z: 0.0, w: 0.995 };

        sim.move_head(new_pos, new_rot).await;

        let state = sim.get_state().await;
        assert!((state.head_position.x - 1.0).abs() < 0.001);
    }

    #[tokio::test]
    async fn test_voice_command() {
        let sim = XRSimulator::new();
        sim.speak("open menu").await;

        let state = sim.get_state().await;
        assert_eq!(state.voice_input, Some("open menu".to_string()));
    }

    #[tokio::test]
    async fn test_safe_space_toggle() {
        let sim = XRSimulator::new();

        sim.toggle_safe_space(true).await;
        assert!(sim.get_state().await.is_in_safe_space);

        sim.toggle_safe_space(false).await;
        assert!(!sim.get_state().await.is_in_safe_space);
    }

    #[tokio::test]
    async fn test_feature_check() {
        let sim = XRSimulator::new();

        assert!(sim.has_feature("eye_tracking"));
        assert!(sim.has_feature("voice_control"));
        assert!(!sim.has_feature("unknown_feature"));
    }

    #[tokio::test]
    async fn test_caption_generator() {
        let generator = SimulatedCaptionGenerator::new();
        let caption = generator.generate_caption("Hello world").await;

        assert_eq!(caption.text, "Hello world");
        assert!(caption.confidence > 0.9);
    }
}
